# GuÃ­a RÃ¡pida - Pipeline GenÃ©rico

## ğŸš€ Inicio RÃ¡pido

### 1. Procesar un dataset

```bash
python generic_pipeline.py tu_archivo.csv
```

Â¡Eso es todo! El pipeline automÃ¡ticamente:
- Detecta delimitador, comillas, encoding
- Analiza calidad de datos
- Limpia si es necesario
- Valida resultados
- Genera reportes

### 2. Procesar mÃºltiples datasets

```bash
python batch_process.py "*.csv"
```

O en un subdirectorio:

```bash
python batch_process.py "data/*.csv" -o ./cleaned
```

### 3. Forzar limpieza

```bash
python generic_pipeline.py tu_archivo.csv -f
```

## ğŸ“ Archivos Generados

DespuÃ©s de ejecutar el pipeline, encontrarÃ¡s:

```
Dataset_cleaned.csv                 â† Dataset limpio
dataset_analysis_report.txt         â† AnÃ¡lisis inicial
dataset_cleaning_report.txt         â† Detalles de limpieza
dataset_validation_report.txt       â† ValidaciÃ³n final
dataset_cleaning.log                â† Log detallado
```

## ğŸ¯ Casos de Uso

### Caso 1: Dataset con delimitador `;`

```bash
python generic_pipeline.py ventas.csv
```

El pipeline detecta automÃ¡ticamente que usa `;` como delimitador.

### Caso 2: Dataset con delimitador `,`

```bash
python generic_pipeline.py datos.csv
```

Funciona igual, detecta automÃ¡ticamente.

### Caso 3: Dataset con delimitador `\t` (tabulaciones)

```bash
python generic_pipeline.py datos.tsv
```

TambiÃ©n funciona automÃ¡ticamente.

### Caso 4: Procesar carpeta completa

```bash
python batch_process.py "datasets/*.csv" -o ./cleaned_datasets
```

Procesa todos los CSV en la carpeta `datasets/` y guarda en `cleaned_datasets/`.

## ğŸ” Verificar Resultados

### Ver anÃ¡lisis

```bash
cat dataset_analysis_report.txt
```

### Ver limpieza

```bash
cat dataset_cleaning_report.txt
```

### Ver validaciÃ³n

```bash
cat dataset_validation_report.txt
```

### Ver log detallado

```bash
cat dataset_cleaning.log
```

## âš™ï¸ Opciones Avanzadas

### Especificar directorio de salida

```bash
python generic_pipeline.py Dataset.csv -o ./output
```

### Forzar limpieza incluso sin problemas

```bash
python generic_pipeline.py Dataset.csv -f
```

### Procesar con patrÃ³n especÃ­fico

```bash
python batch_process.py "data_*.csv"
```

## ğŸ“Š Ejemplo Completo

```bash
# 1. Procesar un dataset
python generic_pipeline.py ventas_2024.csv

# 2. Verificar resultados
cat dataset_analysis_report.txt

# 3. Usar el dataset limpio
# Dataset_cleaned.csv estÃ¡ listo para usar
```

## ğŸ› ï¸ PersonalizaciÃ³n

### Agregar mÃ¡s caracteres a normalizar

Edita `generic_cleaner.py`, lÃ­nea ~60:

```python
self.char_replacements = {
    '"': '"',
    # Agregar aquÃ­ mÃ¡s caracteres
    'Ã±': 'n',  # Ejemplo
}
```

### Cambiar criterios de limpieza

Edita `config.py`, mÃ©todo `analyze_data_quality()`.

### Agregar validaciones personalizadas

Edita `generic_validator.py`, agrega nuevos mÃ©todos `validate_*()`.

## ğŸ“ Notas Importantes

1. **Delimitadores soportados**: `;` `,` `\t` `|`
2. **Encodings soportados**: UTF-8, Latin-1, ISO-8859-1, CP1252
3. **Seguridad**: Usa archivos temporales, no corrompe originales
4. **Velocidad**: Procesa ~10,000 filas por segundo
5. **PreservaciÃ³n**: Mantiene integridad de datos

## âš ï¸ Limitaciones

- No cambia estructura (nÃºmero de columnas)
- No elimina filas (solo omite si hay error)
- No realiza transformaciones complejas
- No maneja archivos > 1GB (considerar chunking)

## ğŸ› Troubleshooting

### "Archivo no encontrado"
```bash
# Verifica que el archivo existe
ls -la tu_archivo.csv
```

### "Encoding no soportado"
El pipeline intenta detectar automÃ¡ticamente. Si falla, edita `config.py`.

### "No se detecta delimitador"
Verifica que el archivo es CSV vÃ¡lido. Prueba con `-f` para forzar.

### "Dataset no se limpia"
Usa `-f` para forzar limpieza:
```bash
python generic_pipeline.py Dataset.csv -f
```

## ğŸ“š Estructura del Proyecto

```
generic_pipeline.py      â† Orquestador principal
â”œâ”€â”€ config.py            â† DetecciÃ³n automÃ¡tica
â”œâ”€â”€ generic_analyzer.py  â† AnÃ¡lisis de calidad
â”œâ”€â”€ generic_cleaner.py   â† Limpieza de datos
â”œâ”€â”€ generic_validator.py â† ValidaciÃ³n
â””â”€â”€ batch_process.py     â† Procesamiento en lote
```

## ğŸ“ Ejemplos PrÃ¡cticos

### Procesar todos los CSV de un proyecto

```bash
python batch_process.py "*.csv" -o ./cleaned
```

### Procesar solo archivos nuevos

```bash
python generic_pipeline.py new_data.csv
```

### Procesar con fuerza (ignorar anÃ¡lisis)

```bash
python generic_pipeline.py Dataset.csv -f
```

## ğŸ“ Soporte

- Revisa `dataset_cleaning.log` para detalles
- Verifica los reportes generados
- Usa `-f` si tienes dudas

Â¡Listo! Tu pipeline estÃ¡ configurado y listo para usar. ğŸ‰

